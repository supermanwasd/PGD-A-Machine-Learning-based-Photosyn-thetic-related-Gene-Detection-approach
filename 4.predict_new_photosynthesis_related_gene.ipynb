{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"feature_dataset/Dataset_an.csv\")\n",
    "df_unkonw = pd.read_csv(\"feature_dataset/Dataset_unan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = []\n",
    "for i in df_data.columns:\n",
    "    if i != \"GeneID\":\n",
    "        if i != \"ps\":\n",
    "            feat.append(i)\n",
    "def lgb_p(x):\n",
    "    y = 0\n",
    "    if x > 0.5:\n",
    "        y = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 76.1ms\tremaining: 76.1ms\n",
      "1:\ttotal: 105ms\tremaining: 0us\n",
      "[22:54:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 220, number of negative: 405\n",
      "[LightGBM] [Info] Total Bins 68644\n",
      "[LightGBM] [Info] Number of data points in the train set: 625, number of used features: 331\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.352000 -> initscore=-0.610260\n",
      "[LightGBM] [Info] Start training from score -0.610260\n"
     ]
    }
   ],
   "source": [
    "df11 = pd.DataFrame()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=2020)\n",
    "\n",
    "clf = rf.fit(df_data[feat],df_data[\"ps\"])\n",
    "rf_y = clf.predict(df_unkonw[feat])\n",
    "\n",
    "model=CatBoostClassifier(\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"AUC\",\n",
    "            task_type=\"CPU\",\n",
    "            learning_rate=0.1,\n",
    "            iterations=2,\n",
    "            random_seed=2020,\n",
    "            od_type=\"Iter\",\n",
    "            depth=8,\n",
    "            early_stopping_rounds=500)\n",
    "\n",
    "clf = model.fit(df_data[feat],df_data[\"ps\"],verbose=500)\n",
    "cat_y = clf.predict(df_unkonw[feat])\n",
    "\n",
    "model = XGBClassifier(max_depth=8, silent=0,booster='gbtree',\n",
    "                      random_state=2020)\n",
    "model.fit(df_data[feat],df_data[\"ps\"],eval_metric=\"auc\")\n",
    "xgb_y = model.predict(df_unkonw[feat])\n",
    "\n",
    "train_lgb = lgb.Dataset(data=df_data[feat],label=df_data[\"ps\"])\n",
    "param = {'num_leaves':8, 'num_trees':8, 'objective':'binary','boost_from_average': True,'force_row_wise':True,'metric':'auc','data_random_seed': 2020,'seed': 2020}\n",
    "bst = lgb.train(param, train_lgb)\n",
    "y_pred = bst.predict(df_unkonw[feat])\n",
    "df11[\"lgb\"] = y_pred\n",
    "lgb_y = df11[\"lgb\"].apply(lambda x:lgb_p(x))\n",
    "\n",
    "def vote(x):\n",
    "        y = 0\n",
    "        if abs(x) > 2:\n",
    "            y = 1\n",
    "        return y\n",
    "\n",
    "df_cat = pd.DataFrame(cat_y)#2分\n",
    "df_xgb = pd.DataFrame(xgb_y)#1分\n",
    "df_rf = pd.DataFrame(rf_y)#1.5分\n",
    "df_lgb = pd.DataFrame(list(lgb_y))\n",
    "df = pd.DataFrame(df_lgb[0]*1 + df_xgb[0]*2 + df_rf[0]*1 + df_cat[0]*1)\n",
    "df[1] = df[0].apply(lambda x : vote(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df_unkonw[\"GeneID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[0]\n",
    "del df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('supplement/predict_new_photosynthesis_related_gene.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
